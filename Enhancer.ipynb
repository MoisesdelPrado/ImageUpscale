{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "# import cv2.dnn as dnn\n",
    "# import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sns \n",
    "from kornia.color import rgb_to_ycbcr\n",
    "from typing import Dict, List, Tuple\n",
    "import os, random, math\n",
    "from statistics import mean\n",
    "# import sys\n",
    "# import glob, buscar ficheros en recursivo dentro uno directorio\n",
    "from pathlib import Path\n",
    "import torch, torchvision\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from torchdata.datapipes.iter import IterableWrapper\n",
    "import torchmetrics as metrics\n",
    "from torchinfo import summary\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "# from IPython import display\n",
    "from PIL import Image\n",
    "\n",
    "# Primero proba entrenar los datos desde fondo y integrar transfer learning mas tarde\n",
    "# Usa NAFnet como transfer learning\n",
    "# Cuidarse a las ubicaciones de los hyperparameters\n",
    "# Incluye diversos opciones de resolucion como 1280 x 720, 1920 x 1080, 2560 x 1440, 3840 x 2160? , o tamano original, compatible con jpg, png, pdf, video?\n",
    "# Incluye opciones de clarificacion por los images por usar opencv? (Utilisable solo despues de entrenamiento y convertir vuelta a jpg, etc.)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "data_directory = r'D:\\Documents\\ImageEnhancer\\ImageData'\n",
    "output_directory = r'D:\\Documents\\ImageEnhancer\\PredictionOutput'\n",
    "sample_directory = r'D:\\Documents\\ImageEnhancer\\ForSample'\n",
    "\n",
    "# torch.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_trained_model = dnn.readNet(model='', config='', framework='torch')\n",
    "# dnn.readNetFromTorch\n",
    "# dnn.createTorchImporter\n",
    "\n",
    "# Cargar los COCO class names\n",
    "# with open('object_detection_classes_coco.txt', 'r') as f:\n",
    "#    class_names = f.read().split('\\n')\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir valores del turbacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def blur(photo):\\n    blurred = cv.GaussianBlur(photo, (5, 5), cv.BORDER_DEFAULT)\\n    return blurred'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def blur(photo):\n",
    "    blurred = cv.GaussianBlur(photo, (5, 5), cv.BORDER_DEFAULT)\n",
    "    return blurred\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reiniciar ubicacion de folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\ImageEnhancer\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/\")\n",
    "os.chdir(\"Documents/ImageEnhancer\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar turbaciones y guardarles a cada folder turbada / blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'os.chdir(train_directory)\\nfor train_photo in os.listdir(train_directory):\\n    img = cv.imread(train_photo)\\n    if img is not None:\\n        print(\"Image read\")\\n    else:\\n        print(\"Not read\")\\n    blurred = blur(img)\\n    # Guardarlo a folder BlurredTrain\\n    cv.imwrite(os.path.join(blurred_train_directory, train_photo), blurred)\\n    print(\"Saved {train_photo} to BlurredTrain\")\\n    \\nos.chdir(test_directory)\\nfor test_photo in os.listdir(test_directory):\\n    img = cv.imread(test_photo)\\n    if img is not None:\\n        print(\"Image read\")\\n    else:\\n        print(\"Not read\")\\n    blurred = blur(img)\\n    # Guardarlo a portfolio BlurredTest\\n    cv.imwrite(os.path.join(blurred_test_directory, test_photo), blurred)\\n    print(\"Saved {test_photo} to BlurredTest\")'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"os.chdir(train_directory)\n",
    "for train_photo in os.listdir(train_directory):\n",
    "    img = cv.imread(train_photo)\n",
    "    if img is not None:\n",
    "        print(\"Image read\")\n",
    "    else:\n",
    "        print(\"Not read\")\n",
    "    blurred = blur(img)\n",
    "    # Guardarlo a folder BlurredTrain\n",
    "    cv.imwrite(os.path.join(blurred_train_directory, train_photo), blurred)\n",
    "    print(\"Saved {train_photo} to BlurredTrain\")\n",
    "    \n",
    "os.chdir(test_directory)\n",
    "for test_photo in os.listdir(test_directory):\n",
    "    img = cv.imread(test_photo)\n",
    "    if img is not None:\n",
    "        print(\"Image read\")\n",
    "    else:\n",
    "        print(\"Not read\")\n",
    "    blurred = blur(img)\n",
    "    # Guardarlo a portfolio BlurredTest\n",
    "    cv.imwrite(os.path.join(blurred_test_directory, test_photo), blurred)\n",
    "    print(\"Saved {test_photo} to BlurredTest\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribuir los canales del RGB verso YCbCr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelsplit_output(input):\n",
    "  input = rgb_to_ycbcr(input)\n",
    "  y, u, v = input.chunk(dim=-3, chunks=3)\n",
    "  return y, u, v\n",
    "\n",
    "# Pude seran util? Ajuste contrast para producir images mas claro\n",
    "# Porque cv no es compatible con pytorch, pude ser util despues de prediccion / traversar de modelo\n",
    "def he_hsv(input):\n",
    "    img_hsv = cv.cvtColor(input, cv.COLOR_RGB2HSV)\n",
    "\n",
    "    # Histogram equalisation on the V-channel\n",
    "    img_hsv[:, :, 2] = cv.equalizeHist(img_hsv[:, :, 2])\n",
    "\n",
    "    # convert image back from HSV to RGB\n",
    "    image_hsv = cv.cvtColor(img_hsv, cv.COLOR_HSV2RGB)\n",
    "    \n",
    "    return image_hsv\n",
    "\n",
    "def clahe_hsv(img):\n",
    "    hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    h, s, v = hsv_img[:,:,0], hsv_img[:,:,1], hsv_img[:,:,2]\n",
    "    \n",
    "    # Puede ajuste hyperparameters aqui\n",
    "    clahe = cv.createCLAHE(clipLimit = 15.0, tileGridSize = (20,20))\n",
    "    v = clahe.apply(v)\n",
    "\n",
    "    hsv_img = np.dstack((h,s,v))\n",
    "\n",
    "    rgb = cv.cvtColor(hsv_img, cv.COLOR_HSV2RGB)\n",
    "    \n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como extractar el y channel y reajuntar despues asi? \n",
    "upscale_factor = 4\n",
    "resize_size = 448\n",
    "\n",
    "class ImageFolderCustom(Dataset):\n",
    "    def __init__(self,\n",
    "                 target_dir: str,\n",
    "                 resize_size: int,\n",
    "                 upscale_factor: int,) -> None:\n",
    "        # Get image paths\n",
    "        self.paths = list(Path(target_dir).glob(\"*.jpg\"))\n",
    "\n",
    "        self.hr_transform = transforms.Compose([\n",
    "            transforms.Resize(size=(resize_size, resize_size), interpolation=Image.BICUBIC),\n",
    "            # transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.lr_transform = transforms.Compose([\n",
    "            transforms.Resize(size=(resize_size // upscale_factor, resize_size // upscale_factor), interpolation=Image.BICUBIC),\n",
    "            # transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    # 4. Create function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        # Open image via path and returns it\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path)\n",
    "    \n",
    "    # 5. Overwrite __len__() method\n",
    "    def __len__(self) -> int:\n",
    "        # Returns total no. of samples\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. Overwrite __getitem__() method\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        # Returns one sample of data, data and label (X, y)\n",
    "        img = self.load_image(index)\n",
    "        img_path  = self.paths[index].name #  expects path in data_folder/class_name/image.jpeg\n",
    "        # High res\n",
    "        img_hr = self.hr_transform(img)\n",
    "        # Low res\n",
    "        img_lr = self.lr_transform(img)\n",
    "\n",
    "\n",
    "        return {\"path\": img_path, \"hr\": img_hr, \"lr\": img_lr,}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = ImageFolderCustom(target_dir=data_directory,\n",
    "                                resize_size=resize_size,\n",
    "                                upscale_factor=upscale_factor)\n",
    "\n",
    "train_data, test_data = random_split(image_data, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averiguar otra vez si hace falta el shuffle o no, Como comparar el train y el blurred train si es shuffled?\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "num_workers = os.cpu_count() // 4\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=0,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "train_batches = math.ceil(len(train_data) // BATCH_SIZE)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=0,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True)\n",
    "\n",
    "test_batches = math.ceil(len(test_data) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como convertir desde calidad baja verso calidad alta?\n",
    "# Primera sigue a los ejemplos, luego usar los que te hizo convertiran con turbacion\n",
    "# Como compresar hidden units verso el siguiente layer?\n",
    "# Los hyperparameters beneficie de poner en multiples de 8\n",
    "class ResolutionEnhancer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_channels: int,\n",
    "                 hidden_units: int,\n",
    "                 output_channels: int,\n",
    "                 upscale_factor: int,):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"self.weights = nn.Parameter(torch.randn(1, \n",
    "                                                requires_grad=True,\n",
    "                                                dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, \n",
    "                                             requires_grad=True,\n",
    "                                             dtype=torch.float))\"\"\"\n",
    "        # filter_1 = 9 try 5\n",
    "        # filter_2 = 3 try 1\n",
    "        # filter_3 = 5 try 3\n",
    "\n",
    "        padding = 0\n",
    "        stride = 1\n",
    "\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=1,\n",
    "                      stride=stride,\n",
    "                      padding=padding),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=1,\n",
    "                      stride=stride,\n",
    "                      padding=padding),\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=(hidden_units // 2), # 1/2 aqui?\n",
    "                      kernel_size=1,\n",
    "                      stride=stride,\n",
    "                      padding=padding),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(in_channels=(hidden_units // 2),\n",
    "                      out_channels=(hidden_units // 2),\n",
    "                      kernel_size=1,\n",
    "                      stride=stride,\n",
    "                      padding=padding),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "        # El modelo debe reconstruir el image verso resolucion alta aqui\n",
    "        # Va a ver como calcular in_channels y out_channels en el documentacion ?\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=(hidden_units // 2), # Ajuste aqui para arreglar los problemas de shape?\n",
    "                      out_channels=output_channels * (upscale_factor ** 2),\n",
    "                      kernel_size=1,\n",
    "                      stride=stride,\n",
    "                      padding=padding),\n",
    "            # nn.BatchNorm2d(input_channels),\n",
    "            # nn.PixelShuffle(upscale_factor=upscale_factor),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # debe devolver output layer, pude ser multiples\n",
    "        return nn.functional.pixel_shuffle(input = self.output_layer(self.conv_block_2(self.conv_block_1(input))), upscale_factor=upscale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image(model: torch.nn.Module, \n",
    "                  img: torch.Tensor,\n",
    "                  upscale_factor: int,):\n",
    "    \n",
    "    \"\"\"Predict the result based on input image and restore the image as RGB.\"\"\"\n",
    "    lr_size = resize_size // upscale_factor\n",
    "    y_channel_transform = transforms.Compose([transforms.ToPILImage()])\n",
    "    aux_channel_transform = transforms.Compose([transforms.Resize(size=(lr_size * upscale_factor, lr_size * upscale_factor), interpolation=Image.BICUBIC),\n",
    "                                               transforms.ToPILImage()])\n",
    "    output_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    # print(img.shape)\n",
    "    # torch.squeeze(img, 1)\n",
    "\n",
    "    # Si el image es grayscale?\n",
    "    if img.shape[1] == 1:\n",
    "        output_img = model(img)\n",
    "        \n",
    "    else:\n",
    "        y, u, v = channelsplit_output(img)\n",
    "\n",
    "        # Restore the image in RGB color space.\n",
    "        # print(f\"Y channel: {y.shape}\")\n",
    "        y_model = model(y)\n",
    "        print(y_model.shape)\n",
    "        y_channel_output = y_channel_transform(torch.squeeze(torch.permute(y_model, (1, 0, 2, 3)), 1)) # ? \n",
    "        print(f\"Y channel after model: {y_channel_output.shape}\")\n",
    "        u_channel_output = aux_channel_transform(torch.squeeze(torch.permute(u, (1, 0, 2, 3)), 1))\n",
    "        print(f\"U channel after resize: {u_channel_output.shape}\")\n",
    "        v_channel_output = aux_channel_transform(torch.squeeze(torch.permute(v, (1, 0, 2, 3)), 1))\n",
    "        print(f\"V channel after resize: {v_channel_output.shape}\")\n",
    "    \n",
    "        # Debemos leer el image primera? O es problema de dispositivo?\n",
    "        remerged = Image.merge(mode='YCbCr', bands=(y_channel_output, u_channel_output, v_channel_output)).convert('RGB')\n",
    "    \n",
    "        output_img = output_transform(remerged).unsqueeze(dim=0)\n",
    "        \n",
    "        # print(\"Has logrado aqui\")\n",
    "        \n",
    "    return output_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir hiperparametros del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.01\n",
    "\n",
    "# adam: decay of first order momentum of gradient\n",
    "b1 = 0.5\n",
    "\n",
    "# adam: decay of second order momentum of gradient\n",
    "b2 = 0.999\n",
    "\n",
    "# epoch from which to start lr decay\n",
    "decay_epoch = 20\n",
    "\n",
    "upscale_factor = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time: .3f} seconds\")\n",
    "\n",
    "    return total_time\n",
    "\n",
    "# random_tensor = torch.rand(size=(3, 224, 224)) # height, width, colour channels for images\n",
    "\n",
    "\"\"\"tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                      dtype=None,\n",
    "                      device=\"gpu\",\n",
    "                      requires_grad=False)\"\"\"\n",
    "\n",
    "# Se conoce tambien a criterion \n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "model = ResolutionEnhancer(input_channels=1,\n",
    "                           hidden_units=64,\n",
    "                           output_channels=1,\n",
    "                           upscale_factor=upscale_factor).to(device)\n",
    "# print(model)\n",
    "\n",
    "optimiser = optim.Adam(params=model.parameters(),\n",
    "                       lr=learn_rate,\n",
    "                       betas=(b1, b2))\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimiser)\n",
    "\n",
    "psnr = metrics.PeakSignalNoiseRatio().to(device)\n",
    "ssim = metrics.StructuralSimilarityIndexMeasure().to(device)\n",
    "\n",
    "# blob = dnn.blobFromImage(image=img, scalefactor=0.01, size=(224, 224), mean=.to(device)(104, 117, 123))\n",
    "\n",
    "# set the input blob for the neural network\n",
    "# model.setInput(blob)\n",
    "# forward pass image blob through the model\n",
    "# outputs = model.forward()\n",
    "# out = next(iter(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hace los pasos de entrenacion en funcionas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader_iter: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimiser: torch.optim.Optimizer,\n",
    "               device: torch.device = device):\n",
    "\n",
    "    # Devuelve el medio de los valores de un corre\n",
    "    train_results = {\"PSNR\": Avg_PSNR,\n",
    "                     \"SSIM\": Avg_SSIM,\n",
    "                     \"train_loss\": train_loss}\n",
    "\n",
    "    PSNR, SSIM = [], []\n",
    "    train_loss = 0\n",
    "\n",
    "    \n",
    "    # Poner el modelo en modo del entrenamiento\n",
    "    model.train()\n",
    "\n",
    "    for i in range(train_batches):\n",
    "\n",
    "        try:\n",
    "            img = next(dataloader_iter)\n",
    "\n",
    "        except StopIteration:\n",
    "            dataloader_iter = iter(train_dataloader)\n",
    "            img = next(dataloader_iter)\n",
    "\n",
    "\n",
    "        lr_img = img[\"lr\"]\n",
    "        hr_img = img[\"hr\"]\n",
    "\n",
    "\n",
    "        # Pasar los datos a modelo al frente en utilisaban el funcion forward\n",
    "        train_pred = upscale_image(model=model,\n",
    "                                   img=lr_img,\n",
    "                                   upscale_factor=upscale_factor)\n",
    "\n",
    "        # Busca forma de compararles con en el image original / alta calidad\n",
    "        PSNR.append(psnr(hr_img, train_pred))\n",
    "        SSIM.append(ssim(hr_img, train_pred))\n",
    "\n",
    "        # Calcular losses/danos (Differencia entre predicion y actual data), en este caso diferencia entre PSNR original y predicion\n",
    "        loss = loss_fn(hr_img, train_pred)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Poner el optimiser a cero\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Loss atras?\n",
    "        torch.Tensor.backward(loss)\n",
    "\n",
    "        # Hacer progreso al optimiser\n",
    "        optimiser.step()\n",
    "        \n",
    "    \n",
    "    # Tomar loss average por el lungo del dataloader\n",
    "    train_loss /= len(dataloader_iter)\n",
    "    Avg_PSNR = mean(PSNR)\n",
    "    Avg_SSIM = mean(SSIM)\n",
    "\n",
    "    return train_results\n",
    "\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader_iter: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device = device):\n",
    "    \n",
    "    # Devuelve el medio de los valores de un corre\n",
    "    test_results = {\"PSNR\": Avg_PSNR,\n",
    "                    \"SSIM\": Avg_SSIM,\n",
    "                    \"test_loss\": test_loss}\n",
    "    \n",
    "    test_loss = 0\n",
    "    PSNR, SSIM = [], []\n",
    "\n",
    "    # Poner en modo eval\n",
    "    model.eval()\n",
    "\n",
    "    # Iniciar modo inference context manager\n",
    "    with torch.inference_mode():\n",
    "        for i in range(test_batches):\n",
    "            try:\n",
    "                img = next(dataloader_iter)\n",
    "\n",
    "            except StopIteration:\n",
    "                dataloader_iter = iter(test_dataloader)\n",
    "                img = next(dataloader_iter)\n",
    "\n",
    "            # Enviar datos a device tarjeta\n",
    "            lr_img = img[\"lr\"]\n",
    "            hr_img = img[\"hr\"]\n",
    "\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = upscale_image(model=model,\n",
    "                                      img=lr_img,\n",
    "                                      upscale_factor=upscale_factor)\n",
    "\n",
    "            # Busca forma de compararles con en el image original / alta calidad\n",
    "            PSNR.append(psnr(hr_img, test_pred))\n",
    "            SSIM.append(ssim(hr_img, test_pred))\n",
    "\n",
    "            # 2. Calc loss/acc, adaptar a comparacion con PSNR y SSIM?\n",
    "            loss = loss_fn(hr_img, test_pred)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        # Ajustar metrics y imprintir\n",
    "        test_loss /= len(dataloader_iter)\n",
    "        Avg_PSNR = mean(PSNR)\n",
    "        Avg_SSIM = mean(SSIM)\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# ?\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               device: torch.device = device):\n",
    "    \n",
    "    # Returns dictionary w/ results of model\n",
    "    loss = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, img in tqdm(enumerate(dataloader)):\n",
    "\n",
    "            lr_img = img[\"lr\"]\n",
    "            hr_img = img[\"hr\"]\n",
    "\n",
    "            # Make predictions\n",
    "            pred_output = upscale_image(model=model,\n",
    "                                        img=lr_img,\n",
    "                                        upscale_factor=upscale_factor)\n",
    "\n",
    "            # Accumulate loss and acc values per batch\n",
    "            loss += loss_fn(hr_img, pred_output)\n",
    "            \"\"\"acc += accuracy_fn(y_true=y,\n",
    "                               y_pred=y_pred.argmax(dim=1))\"\"\"\n",
    "            \n",
    "        # Scale loss and acc to find avg loss/acc per batch\n",
    "        loss /=  len(dataloader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__, # works only when model was created with class)\n",
    "            \"model_loss\": loss.item(),}\n",
    "\n",
    "\n",
    "def run_training(model: torch.nn.Module,\n",
    "                 train_dataloader: torch.utils.data.DataLoader,\n",
    "                 test_dataloader: torch.utils.data.DataLoader,\n",
    "                 optimiser: torch.optim.Optimizer,\n",
    "                 loss_fn: torch.nn.Module,\n",
    "                 epochs: int,\n",
    "                 seed: None,\n",
    "                 device = device):\n",
    "    \n",
    "    start_timer = timer()\n",
    "    \n",
    "    # 2. Crear diccionario de resultas vacia\n",
    "    # # Devuelve el medio de los valores de un epoca\n",
    "    results = {\"train_loss\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"PSNR_train_epoch\": [],\n",
    "               \"SSIM_train_epoch\": [],\n",
    "               \"PSNR_test_epoch\": [],\n",
    "               \"SSIM_test_epoch\": [],}\n",
    "    \n",
    "    PSNR_train_untrained = []\n",
    "    SSIM_train_untrained = []\n",
    "    PSNR_test_untrained = []\n",
    "    SSIM_test_untrained = []\n",
    "\n",
    "    # Crear dataloader separado por ese iteracion\n",
    "    train_dataloader_untrained = iter(train_dataloader)\n",
    "\n",
    "    # Se va atrapado aqui\n",
    "    for i in range(train_batches):\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            train_img = next(train_dataloader_untrained)\n",
    "\n",
    "        except StopIteration:\n",
    "            dataloader_iter = iter(train_dataloader)\n",
    "            train_img = next(train_dataloader_untrained)\n",
    "\n",
    "        # print(train_img['hr'].shape)\n",
    "\n",
    "\n",
    "        # print(train_img[\"lr\"].shape)\n",
    "\n",
    "        train_pred_img = upscale_image(model=model,\n",
    "                                       img=train_img[\"lr\"].to(device),\n",
    "                                       upscale_factor=upscale_factor)\n",
    "\n",
    "        # print(train_pred_img.shape)\n",
    "        \n",
    "        PSNR_train_untrained.append(psnr(train_img[\"hr\"].to(device), torch.permute(train_pred_img, (1, 0, 2, 3)).to(device)))\n",
    "\n",
    "\n",
    "        # Hace falta hacer en grayscale antes tomar el SSIM?\n",
    "        SSIM_train_untrained.append(ssim(train_img[\"hr\"].to(device), torch.permute(train_pred_img, (1, 0, 2, 3)).to(device)))\n",
    "\n",
    "        print(torch.cuda.memory_allocated())\n",
    "\n",
    "    # Crear dataloader separado por ese iteracion\n",
    "    test_dataloader_untrained = iter(test_dataloader)\n",
    "\n",
    "    for i in range(test_batches):\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            test_img = next(test_dataloader_untrained)\n",
    "\n",
    "        except StopIteration:\n",
    "            dataloader_iter = iter(test_dataloader)\n",
    "            test_img = next(test_dataloader_untrained)\n",
    "\n",
    "        test_pred_img = upscale_image(model=model,\n",
    "                                      img=test_img[\"lr\"].to(device), \n",
    "                                      upscale_factor=upscale_factor)\n",
    "\n",
    "        PSNR_test_untrained.append(psnr(test_img[\"hr\"].to(device), torch.permute(test_pred_img, (1, 0, 2, 3)).to(device)))\n",
    "\n",
    "        # Hace falta hacer en grayscale antes tomar el SSIM?\n",
    "        SSIM_test_untrained.append(ssim(test_img[\"hr\"].to(device), torch.permute(test_pred_img, (1, 0, 2, 3)).to(device)))\n",
    "\n",
    "        print(torch.cuda.memory_allocated())\n",
    "\n",
    "    print(\"has logrado aqui\")\n",
    "\n",
    "    results[\"train_loss\"].append(0)\n",
    "    results[\"test_loss\"].append(0)\n",
    "    results[\"PSNR_train_epoch\"].append(mean(PSNR_train_untrained))\n",
    "    results[\"SSIM_train_epoch\"].append(mean(SSIM_train_untrained))\n",
    "    results[\"PSNR_test_epoch\"].append(mean(PSNR_test_untrained))\n",
    "    results[\"SSIM_test_epoch\"].append(mean(SSIM_test_untrained))\n",
    "\n",
    "    if seed:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # 3. Hacer lazo a traves de entrenamiento\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch: {epoch}\\n---------\")\n",
    "\n",
    "        print(torch.cuda.memory_allocated())\n",
    "\n",
    "        train_dataloader_iter = iter(train_dataloader)\n",
    "\n",
    "        test_dataloader_iter = iter(test_dataloader)\n",
    "        \n",
    "        train_results = train_step(model=model,\n",
    "                                data_loader_iter=train_dataloader_iter,\n",
    "                                loss_fn=loss_fn,\n",
    "                                optimiser=optimiser,\n",
    "                                device=device)\n",
    "    \n",
    "        test_results = test_step(model=model,\n",
    "                              data_loader_iter=test_dataloader_iter,\n",
    "                              loss_fn=loss_fn,\n",
    "                              device=device)\n",
    "        \n",
    "        # Ponerle aqui?\n",
    "        scheduler.step()\n",
    "\n",
    "        # Adaptar a nuevos parametros de evaluacion\n",
    "        # No lo se si podamos usarlo en convertirando verso train_step, test_step funcionas\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"\\nEpoch: {epoch} | Train loss: {train_results['train_loss']:.4f} | Test loss: {test_results['test_loss']:.4f}\")\n",
    "            print(model.state_dict())\n",
    "\n",
    "        # 5. Poner al dia el diccionario de resultas\n",
    "        results[\"train_loss\"].append(train_results[\"train_loss\"])\n",
    "        results[\"test_loss\"].append(test_results[\"test_loss\"])\n",
    "        results[\"PSNR_train_epoch\"].append(train_results[\"PSNR\"])\n",
    "        results[\"SSIM_train_epoch\"].append(train_results[\"SSIM\"])\n",
    "        results[\"PSNR_test_epoch\"].append(test_results[\"PSNR\"])\n",
    "        results[\"SSIM_test_epoch\"].append(test_results[\"SSIM\"])\n",
    "\n",
    "        end_timer = timer()\n",
    "        total_train_time_model = print_train_time(start=start_timer, \n",
    "                                                  end=end_timer,\n",
    "                                                  device=str(next(model.parameters()).device))\n",
    "        print(total_train_time_model)\n",
    "\n",
    "    # 6. Devuelve resultados \n",
    "    return results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averiguar el estado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of ResolutionEnhancer(\n",
      "  (conv_block_1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (conv_block_2): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): GELU(approximate='none')\n",
      "  )\n",
      "  (output_layer): Sequential(\n",
      "    (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el entranimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 448, 448])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pic should be 2/3 dimensional. Got 4 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[357], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Adaptar para este modelo\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Pienso que el accuracy function debe ser del PSNR y SSIM? O sea una comparacion con los PSNR y SSIM del original contra lo del predicion\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                             \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[355], line 192\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(model, train_dataloader, test_dataloader, optimiser, loss_fn, epochs, seed, device)\u001b[0m\n\u001b[0;32m    185\u001b[0m     train_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_dataloader_untrained)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# print(train_img['hr'].shape)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# print(train_img[\"lr\"].shape)\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m train_pred_img \u001b[38;5;241m=\u001b[39m \u001b[43mupscale_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_img\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mupscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupscale_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# print(train_pred_img.shape)\u001b[39;00m\n\u001b[0;32m    198\u001b[0m PSNR_train_untrained\u001b[38;5;241m.\u001b[39mappend(psnr(train_img[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mpermute(train_pred_img, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)))\n",
      "Cell \u001b[1;32mIn[352], line 26\u001b[0m, in \u001b[0;36mupscale_image\u001b[1;34m(model, img, upscale_factor)\u001b[0m\n\u001b[0;32m     24\u001b[0m y_model \u001b[38;5;241m=\u001b[39m model(y)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_model\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 26\u001b[0m y_channel_output \u001b[38;5;241m=\u001b[39m \u001b[43my_channel_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# ? \u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY channel after model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_channel_output\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m u_channel_output \u001b[38;5;241m=\u001b[39m aux_channel_transform(torch\u001b[38;5;241m.\u001b[39msqueeze(torch\u001b[38;5;241m.\u001b[39mpermute(u, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)), \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32md:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:234\u001b[0m, in \u001b[0;36mToPILImage.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pil_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:266\u001b[0m, in \u001b[0;36mto_pil_image\u001b[1;34m(pic, mode)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pic, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m}:\n\u001b[1;32m--> 266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be 2/3 dimensional. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mndimension()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;66;03m# if 2D image, add channel dimension (CHW)\u001b[39;00m\n\u001b[0;32m    270\u001b[0m         pic \u001b[38;5;241m=\u001b[39m pic\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: pic should be 2/3 dimensional. Got 4 dimensions."
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Adaptar para este modelo\n",
    "# Pienso que el accuracy function debe ser del PSNR y SSIM? O sea una comparacion con los PSNR y SSIM del original contra lo del predicion\n",
    "model_results = run_training(model=model,\n",
    "                             train_dataloader=train_dataloader,\n",
    "                             test_dataloader=test_dataloader,\n",
    "                             optimiser=optimiser,\n",
    "                             loss_fn=loss_function,\n",
    "                             epochs=epochs,\n",
    "                             seed=None,\n",
    "                             device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def PSNR(img1, img2):\n",
    "    mse = np.mean(np.square(np.subtract(img1.astype(np.float64),\n",
    "                                        img2.astype(np.float64))))\n",
    "    if mse == 0:\n",
    "        return np.Inf\n",
    "\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX) - 10 * math.log10(mse)\"\"\"\n",
    "\n",
    "results_df = pd.DataFrame(index=range(0, epochs), data=model_results)\n",
    "\n",
    "print(results_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir functions para mostrar plots de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pude beneficiarnos a usar seaborn aqui\n",
    "def plot_loss_curves(results: Dict[str, List[float]]):\n",
    "    \"\"\"Plots training curves of a results dictionary\"\"\"\n",
    "    # Get loss values of results dict(train and test)\n",
    "    train_loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "    PSNR_train = results[\"PSNR_train_epoch\"]\n",
    "    SSIM_train = results[\"SSIM_train_epoch\"]\n",
    "    PSNR_test = results[\"PSNR_test_epoch\"]\n",
    "    SSIM_test = results[\"SSIM_test_epoch\"]\n",
    "\n",
    "    # Establecer plot\n",
    "    plot.figure(figsize=(15, 7))\n",
    "\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "    # Plot the responses for different events and regions\n",
    "    sns.lineplot(x=\"epoch\", y=\"train_loss\",\n",
    "                # hue=\"region\", style=\"event\",\n",
    "                 data=train_loss)\n",
    "    \n",
    "    sns.lineplot(x=\"epoch\", y=\"test_loss\",\n",
    "                # hue=\"region\", style=\"event\",\n",
    "                 data=test_loss)\n",
    "    \n",
    "    sns.lineplot(x=\"epoch\", y=\"PSNR_train\",\n",
    "                # hue=\"region\", style=\"event\",\n",
    "                 data=PSNR_train)\n",
    "    \n",
    "    sns.lineplot(x=\"epoch\", y=\"SSIM_train\",\n",
    "                # hue=\"region\", style=\"event\",\n",
    "                 data=SSIM_train)\n",
    "    \n",
    "    sns.lineplot(x=\"epoch\", y=\"PSNR_test\",\n",
    "                # hue=\"region\", style=\"event\",\n",
    "                 data=PSNR_test)\n",
    "    \n",
    "    sns.lineplot(x=\"epoch\", y=\"SSIM_test\",\n",
    "                # hue=\"region\", style=\"event\",\n",
    "                 data=SSIM_test)\n",
    "\n",
    "\n",
    "def pred_and_plot_image(model: torch.nn.Module,\n",
    "                        image_path: str,\n",
    "                        transform=None,\n",
    "                        device=device):\n",
    "    \n",
    "    \"\"\"Makes prediction on a target image w/ trained model and plots\"\"\"\n",
    "    # Load image\n",
    "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32).to(device)\n",
    "\n",
    "    # Divide image pixel values by 255 to turn between [0, 1] ?\n",
    "    target_image = target_image / 255.0\n",
    "\n",
    "    # Transform if any\n",
    "    if transform:\n",
    "        target_image = transform(target_image)\n",
    "\n",
    "    # Make sure the model is on target device\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # Add extra dimension to image (batch size dimension)\n",
    "        target_image = target_image.unsqueeze(0)\n",
    "\n",
    "        # Make predicition on image w/ extra dimension\n",
    "        target_image_pred = model(target_image)\n",
    "    \n",
    "    PSNR = psnr(target_image_pred, target_image) # ?\n",
    "    SSIM = ssim(target_image_pred, target_image) # ?\n",
    "        \n",
    "    plot.imshow(target_image.squeeze().permute(1, 2, 0))\n",
    "    plot.imshow(target_image_pred)\n",
    "    plot.title(f\"PSNR: {PSNR} | SSIM: {SSIM}\")\n",
    "    plot.axis(False)\n",
    "    \n",
    "\n",
    "def predict_random_images(dataset: torch.utils.data.Dataset,\n",
    "                          model: nn.Module,\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int = None,\n",
    "                          transform = None):\n",
    "    \n",
    "    # 2. Adjust display if n too high\n",
    "    if n > 10:\n",
    "        n = 10\n",
    "        display_shape = False\n",
    "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
    "    \n",
    "    # 3. Set random seed\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 4. Get random sample indexes\n",
    "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
    "\n",
    "    # 5. Setup plot\n",
    "    plot.figure(figsize=(16, 8))\n",
    "\n",
    "    # 6. Loop through samples and display random samples \n",
    "    for i, targ_sample in enumerate(random_samples_idx):\n",
    "\n",
    "        target_image = torchvision.io.read_image(dataset[targ_sample]).type(torch.float32).to(device)\n",
    "\n",
    "        # Divide image pixel values by 255 to turn between [0, 1]\n",
    "        target_image = target_image / 255.0\n",
    "\n",
    "        # Transform if any\n",
    "        if transform:\n",
    "            target_image = transform(target_image)\n",
    "\n",
    "         # Make sure the model is on target device\n",
    "        model.to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # Add extra dimension to image (batch size dimension)\n",
    "        target_image = target_image.unsqueeze(0)\n",
    "\n",
    "        # Make predicition on image w/ extra dimension\n",
    "        target_image_pred = model(target_image)\n",
    "\n",
    "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
    "        # Porque permute no va a funcionar??\n",
    "        torch.permute(target_image, (1, 2, 0))\n",
    "\n",
    "    PSNR = psnr(target_image_pred, target_image) # ?\n",
    "    SSIM = ssim(target_image_pred, target_image) # ?\n",
    "\n",
    "    # Plot adjusted samples\n",
    "    plot.subplot(1, n, i+1)\n",
    "    plot.imshow(target_image)\n",
    "    plot.imshow(target_image_pred)\n",
    "    plot.title(f\"PSNR: {PSNR} | SSIM: {SSIM}\")\n",
    "    plot.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(results=model_results)\n",
    "\n",
    "predict_random_images(dataset=test_data,\n",
    "                      model=model,\n",
    "                      n=5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar y Cargar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), PATH)\n",
    "# torch.load()\n",
    "# torch.nn.Module.model.load_state_dict()\n",
    "\n",
    "\n",
    "MODEL_PATH = Path(r\"D:\\Documents\\ImageEnhancer\\Models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"resolution_enhancer.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# if MODEL_SAVE_PATH.is_dir():\n",
    "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)\n",
    "print(f\"Saved model to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "\n",
    "loaded_model = ResolutionEnhancer(input_channels=1,\n",
    "                                  hidden_units=64,\n",
    "                                  output_channels=1,\n",
    "                                  upscale_factor=3) # Solo uno ejemplo\n",
    "\n",
    "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
